{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/deepak/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#importing Keras, Library for deep learning \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib', matplotlib.__version__+'\\n','keras:', keras.__version__+'\\n','sklearn:', sklearn.__version__+'\\n', 'pandas:' + pandas.__version__+'\\n','numpy:'+ numpy.__version__+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset https://www.kaggle.com/oddrationale/mnist-in-csv\n",
    "# preprocessing data\n",
    "trainData = pd.read_csv('/home/deepak/Desktop/deepWork/machineLearning/dataset/mnistData/mnist_train.csv')\n",
    "testData = pd.read_csv('/home/deepak/Desktop/deepWork/machineLearning/dataset/mnistData/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785) (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(trainData.shape, testData.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 785)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trainData.append(testData)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
       "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
       "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
       "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
       "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
       "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
       "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
       "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
       "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
       "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
       "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
       "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
       "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshapping the data because data is in rows and we need matrix for computation\n",
    "# Convert into 28*28*1 using reshape fun (1 because it contains only blackandWhite)\n",
    "# Unsigned integer (0 to 255)\n",
    "data.iloc[1, 1:].values.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing Pixel array in form length width and channel in df_x\n",
    "df_x = data.iloc[:,1:].values.reshape(len(data), 28, 28, 1)\n",
    "# storing labels in y\n",
    "y = data.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now y conatins 0...9 which may have relationship among them\n",
    "# like our model may refer 2 = 2*1\n",
    "# so we will convert it into categorical vectors\n",
    "# like 0 will be [1 0 0 ...0], 1 = [0 1 0 .... 0]\n",
    "#Converting labels to categorical features\n",
    "\n",
    "df_y = keras.utils.to_categorical(y,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x  =  np.array(df_x)\n",
    "df_y  =  np.array(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test train split# test t \n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x,df_y,test_size=0.2,random_state=4)\n",
    "# done with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CNN model#CNN mod \n",
    "model = Sequential()\n",
    "# 32 filter 3*3 size\n",
    "model.add(Convolution2D(32,3,data_format='channels_last',activation='relu',input_shape=(28,28,1)))\n",
    "# reduce number of parameters by getting imporatant params\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten()) # converts all matrix to single vector\n",
    "model.add(Dense(100))    #100 NN nodes \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))     #output on NN will have 10 node as our output will be categorical nodes\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy']) # chose loss fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               540900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 542,230\n",
      "Trainable params: 542,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56000 samples, validate on 14000 samples\n",
      "Epoch 1/30\n",
      "56000/56000 [==============================] - 48s 849us/step - loss: 9.2146 - acc: 0.4263 - val_loss: 7.5909 - val_acc: 0.5282\n",
      "Epoch 2/30\n",
      "56000/56000 [==============================] - 46s 826us/step - loss: 7.4869 - acc: 0.5336 - val_loss: 5.8560 - val_acc: 0.6350\n",
      "Epoch 3/30\n",
      "56000/56000 [==============================] - 47s 834us/step - loss: 5.5506 - acc: 0.6533 - val_loss: 3.5318 - val_acc: 0.7793\n",
      "Epoch 4/30\n",
      "56000/56000 [==============================] - 56s 994us/step - loss: 3.6200 - acc: 0.7732 - val_loss: 2.2944 - val_acc: 0.8556\n",
      "Epoch 5/30\n",
      "56000/56000 [==============================] - 49s 882us/step - loss: 2.6303 - acc: 0.8347 - val_loss: 1.8088 - val_acc: 0.8867\n",
      "Epoch 6/30\n",
      "56000/56000 [==============================] - 57s 1ms/step - loss: 2.3685 - acc: 0.8512 - val_loss: 1.4719 - val_acc: 0.9078\n",
      "Epoch 7/30\n",
      "56000/56000 [==============================] - 56s 997us/step - loss: 2.1549 - acc: 0.8647 - val_loss: 1.5071 - val_acc: 0.9055\n",
      "Epoch 8/30\n",
      "56000/56000 [==============================] - 50s 891us/step - loss: 1.9359 - acc: 0.8783 - val_loss: 1.3256 - val_acc: 0.9169\n",
      "Epoch 9/30\n",
      "56000/56000 [==============================] - 50s 890us/step - loss: 1.6474 - acc: 0.8962 - val_loss: 1.2424 - val_acc: 0.9219\n",
      "Epoch 10/30\n",
      "56000/56000 [==============================] - 49s 881us/step - loss: 1.5794 - acc: 0.9006 - val_loss: 1.0819 - val_acc: 0.9320\n",
      "Epoch 11/30\n",
      "56000/56000 [==============================] - 47s 835us/step - loss: 1.4948 - acc: 0.9059 - val_loss: 1.0419 - val_acc: 0.9344\n",
      "Epoch 12/30\n",
      "56000/56000 [==============================] - 48s 866us/step - loss: 1.4388 - acc: 0.9092 - val_loss: 1.0095 - val_acc: 0.9366\n",
      "Epoch 13/30\n",
      "56000/56000 [==============================] - 51s 916us/step - loss: 1.3150 - acc: 0.9171 - val_loss: 0.9363 - val_acc: 0.9411\n",
      "Epoch 14/30\n",
      "56000/56000 [==============================] - 51s 919us/step - loss: 1.2459 - acc: 0.9214 - val_loss: 0.9954 - val_acc: 0.9376\n",
      "Epoch 15/30\n",
      "56000/56000 [==============================] - 46s 824us/step - loss: 1.2156 - acc: 0.9234 - val_loss: 0.8704 - val_acc: 0.9451\n",
      "Epoch 16/30\n",
      "56000/56000 [==============================] - 41s 737us/step - loss: 1.1408 - acc: 0.9279 - val_loss: 0.8000 - val_acc: 0.9491\n",
      "Epoch 17/30\n",
      "56000/56000 [==============================] - 65s 1ms/step - loss: 1.0847 - acc: 0.9314 - val_loss: 0.8169 - val_acc: 0.9486\n",
      "Epoch 18/30\n",
      "56000/56000 [==============================] - 57s 1ms/step - loss: 1.0503 - acc: 0.9338 - val_loss: 0.8375 - val_acc: 0.9468\n",
      "Epoch 19/30\n",
      "56000/56000 [==============================] - 52s 928us/step - loss: 1.0791 - acc: 0.9317 - val_loss: 0.7934 - val_acc: 0.9499\n",
      "Epoch 20/30\n",
      "56000/56000 [==============================] - 53s 940us/step - loss: 1.0866 - acc: 0.9314 - val_loss: 0.8207 - val_acc: 0.9483\n",
      "Epoch 21/30\n",
      "56000/56000 [==============================] - 52s 928us/step - loss: 1.0350 - acc: 0.9347 - val_loss: 0.7165 - val_acc: 0.9550\n",
      "Epoch 22/30\n",
      "56000/56000 [==============================] - 54s 963us/step - loss: 1.0243 - acc: 0.9354 - val_loss: 0.6676 - val_acc: 0.9581\n",
      "Epoch 23/30\n",
      "56000/56000 [==============================] - 54s 956us/step - loss: 0.9627 - acc: 0.9392 - val_loss: 0.6634 - val_acc: 0.9582\n",
      "Epoch 24/30\n",
      "56000/56000 [==============================] - 53s 949us/step - loss: 0.9570 - acc: 0.9396 - val_loss: 0.7862 - val_acc: 0.9505\n",
      "Epoch 25/30\n",
      "56000/56000 [==============================] - 54s 956us/step - loss: 0.9234 - acc: 0.9418 - val_loss: 0.6615 - val_acc: 0.9583\n",
      "Epoch 26/30\n",
      "56000/56000 [==============================] - 49s 882us/step - loss: 0.9139 - acc: 0.9423 - val_loss: 0.6653 - val_acc: 0.9581\n",
      "Epoch 27/30\n",
      "56000/56000 [==============================] - 41s 736us/step - loss: 0.8881 - acc: 0.9441 - val_loss: 0.7316 - val_acc: 0.9539\n",
      "Epoch 28/30\n",
      "56000/56000 [==============================] - 41s 738us/step - loss: 0.8895 - acc: 0.9440 - val_loss: 0.7301 - val_acc: 0.9537\n",
      "Epoch 29/30\n",
      "56000/56000 [==============================] - 48s 856us/step - loss: 0.8787 - acc: 0.9445 - val_loss: 0.6488 - val_acc: 0.9591\n",
      "Epoch 30/30\n",
      "56000/56000 [==============================] - 43s 774us/step - loss: 0.8641 - acc: 0.9454 - val_loss: 0.6328 - val_acc: 0.9602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff402009b38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=30, validation_data = (x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 3s 212us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.63279334991252312, 0.96021428571428569]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on test and train data\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model so that we can use it later.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----before reshape (28, 28) [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   5  63 197   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  20 254 230  24   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  20 254 254  48   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  20 254 255  48   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  20 254 254  57   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  20 254 254 108   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  16 239 254 143   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 178 254 143   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 178 254 143   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 178 254 162   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 178 254 240   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 113 254 240   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  83 254 245  31   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  79 254 246  38   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 214 254 150   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 144 241   8   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 144 240   2   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 144 254  82   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 230 247  40   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 168 209  31   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADDBJREFUeJzt3W2MXPV1x/HvwVnsxKAKh9SyiMtDC40s1Drt1q0EbVPRpAZRmUgRjaVGboViKqW0qaK2iLwobyqhNg/lRZRoKS6mSkkiEYRf0ETgRKJIKWKhjnlwiwk1wpaxSUEKJGDW9umLvUQb2Lm7nqc75nw/0mru3HNn79H1/nxn7n9m/pGZSKrnjK4bkNQNwy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qah3jXNnZ8bKXMXqce5SKuV1fswbeSyWs+1A4Y+IzcCtwArgnzPzlrbtV7Ga34wrBtmlpBYP5+5lb9v30/6IWAF8CbgS2ABsjYgN/f4+SeM1yGv+TcAzmflsZr4BfA3YMpy2JI3aIOE/D3h+wf2DzbqfERHbI2I2ImbnODbA7iQN08iv9mfmTGZOZ+b0FCtHvTtJyzRI+A8B6xfcf3+zTtJpYJDwPwJcHBEXRsSZwMeBXcNpS9Ko9T3Ul5nHI+LPgW8zP9S3IzOfHFpnkkZqoHH+zLwPuG9IvUgaI9/eKxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlEDzdIbEQeAV4ATwPHMnB5GUxqeWLmytf6TK3+1tf4rn/1+a33/bxw75Z40GQYKf+P3MvOHQ/g9ksbIp/1SUYOGP4EHIuLRiNg+jIYkjcegT/svz8xDEfHzwP0R8d+Z+eDCDZr/FLYDrOI9A+5O0rAMdObPzEPN7VHgHmDTItvMZOZ0Zk5P0X7xSdL49B3+iFgdEWe/uQx8BHhiWI1JGq1BnvavBe6JiDd/z79l5reG0pWkkes7/Jn5LNA+SKzOrXjfua31737pK631/3i9/U/kHy/8w9b68f99rrWu7jjUJxVl+KWiDL9UlOGXijL8UlGGXypqGJ/q0zvYb6863lr/+19Y01o/w6G+ieWZXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKcpxfrVaE54d3Kv9lpaIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkox/nV6kSebK3Pvaf9T8g5miaXZ36pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKmrJcf6I2AFcDRzNzEubdWuArwMXAAeAazPz5dG1qUl19NenWuvr/31MjeiULefMfwew+S3rbgR2Z+bFwO7mvqTTyJLhz8wHgZfesnoLsLNZ3glcM+S+JI1Yv6/512bm4Wb5BWDtkPqRNCYDX/DLzASyVz0itkfEbETMznFs0N1JGpJ+w38kItYBNLdHe22YmTOZOZ2Z01N+zEOaGP2GfxewrVneBtw7nHYkjcuS4Y+Iu4DvAb8cEQcj4jrgFuDDEbEf+P3mvqTTyJLj/Jm5tUfpiiH3ohHIubnW+tNzr7fWL5la1Vp/7cI3TrknTQbf4ScVZfilogy/VJThl4oy/FJRhl8qyq/ufoc7caTnmy8B+Isf/FFr/Vsf8P1b71Se+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkoP8+vgZy15iddt6A+eeaXijL8UlGGXyrK8EtFGX6pKMMvFWX4paKWHOePiB3A1cDRzLy0WXcz8EngxWazmzLzvlE1qcl196/d1lq/gcvG1IlO1XLO/HcAmxdZ/8XM3Nj8GHzpNLNk+DPzQeClMfQiaYwGec1/Q0TsjYgdEXHO0DqSNBb9hv/LwEXARuAw8PleG0bE9oiYjYjZOY71uTtJw9ZX+DPzSGaeyMyTwG3AppZtZzJzOjOnp1jZb5+Shqyv8EfEugV3Pwo8MZx2JI3Lcob67gI+BJwbEQeBvwM+FBEbgQQOANePsEdJI7Bk+DNz6yKrbx9BL+rA8w+tb9/gA+PpQ+PnO/ykogy/VJThl4oy/FJRhl8qyvBLRfnV3cWd9XwO9Pizo/3xKzZc0rN24qmnB9q3BuOZXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKcpy/uDOOD/b4FRGt9ZPvnhpsBxoZz/xSUYZfKsrwS0UZfqkowy8VZfilogy/VJTj/MWdc8f3Wutf+ZvzW+t/9nPPtdb3/9WZPWu/9MetD9WIeeaXijL8UlGGXyrK8EtFGX6pKMMvFWX4paKWHOePiPXAncBaIIGZzLw1ItYAXwcuAA4A12bmy6NrVV343H/+QWt98xX/1Fq/5Pre381/sq+ONCzLOfMfBz6TmRuA3wI+FREbgBuB3Zl5MbC7uS/pNLFk+DPzcGY+1iy/AuwDzgO2ADubzXYC14yqSUnDd0qv+SPiAuCDwMPA2sw83JReYP5lgaTTxLLDHxFnAXcDn87MHy2sZWYyfz1gscdtj4jZiJid49hAzUoanmWFPyKmmA/+VzPzm83qIxGxrqmvA44u9tjMnMnM6cycnmLlMHqWNARLhj8iArgd2JeZX1hQ2gVsa5a3AfcOvz1Jo7Kcj/ReBnwCeDwi9jTrbgJuAb4REdcBzwHXjqZFTbITLPHV3a+9PqZOdKqWDH9mPgQ9/4WvGG47ksbFd/hJRRl+qSjDLxVl+KWiDL9UlOGXivKruzWQX3zXu1vr//enm3rW3nt7+9eGa7Q880tFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUY7zq9W//O6O1vrLJ19rrZ+799WetUW/901j45lfKsrwS0UZfqkowy8VZfilogy/VJThl4pynF+t/nrfx1rrHzv/v1rrZ/y49xRtJ/rqSMPimV8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXilpynD8i1gN3AmuZ/wj2TGbeGhE3A58EXmw2vSkz7xtVo+rGmqufbq1/h9VL/Ib2x6s7y3mTz3HgM5n5WEScDTwaEfc3tS9m5udG156kUVky/Jl5GDjcLL8SEfuA80bdmKTROqXX/BFxAfBB4OFm1Q0RsTcidkTEOT0esz0iZiNido7eb/WUNF7LDn9EnAXcDXw6M38EfBm4CNjI/DODzy/2uMycyczpzJyeYuUQWpY0DMsKf0RMMR/8r2bmNwEy80hmnsjMk8BtQO8ZGSVNnCXDHxEB3A7sy8wvLFi/bsFmHwWeGH57kkZlOVf7LwM+ATweEXuadTcBWyNiI/PDfweA60fSoaSRWM7V/oeAWKTkmL50GvMdflJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIiM8e3s4gXgecWrDoX+OHYGjg1k9rbpPYF9tavYfZ2fma+bzkbjjX8b9t5xGxmTnfWQItJ7W1S+wJ761dXvfm0XyrK8EtFdR3+mY7332ZSe5vUvsDe+tVJb52+5pfUna7P/JI60kn4I2JzRPxPRDwTETd20UMvEXEgIh6PiD0RMdtxLzsi4mhEPLFg3ZqIuD8i9je3i06T1lFvN0fEoebY7YmIqzrqbX1EfDcinoqIJyPiL5v1nR67lr46OW5jf9ofESuYn7f5w8BB4BFga2Y+NdZGeoiIA8B0ZnY+JhwRvwO8CtyZmZc26/4BeCkzb2n+4zwnM/92Qnq7GXi165mbmwll1i2cWRq4BvgTOjx2LX1dSwfHrYsz/ybgmcx8NjPfAL4GbOmgj4mXmQ8CL71l9RZgZ7O8k/k/nrHr0dtEyMzDmflYs/wK8ObM0p0eu5a+OtFF+M8Dnl9w/yCTNeV3Ag9ExKMRsb3rZhaxtpk2HeAFYG2XzSxiyZmbx+ktM0tPzLHrZ8brYfOC39tdnpkbgSuBTzVPbydSzr9mm6ThmmXN3Dwui8ws/VNdHrt+Z7weti7CfwhYv+D++5t1EyEzDzW3R4F7mLzZh4+8OUlqc3u0435+apJmbl5sZmkm4NhN0ozXXYT/EeDiiLgwIs4EPg7s6qCPt4mI1c2FGCJiNfARJm/24V3AtmZ5G3Bvh738jEmZubnXzNJ0fOwmbsbrzBz7D3AV81f8fwB8toseevR1EfD95ufJrnsD7mL+aeAc89dGrgPeC+wG9gMPAGsmqLd/BR4H9jIftHUd9XY580/p9wJ7mp+ruj52LX11ctx8h59UlBf8pKIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8V9f/5rLrg0XATrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 8\n",
    "testImg = trainData.iloc[index:(index+1), 1:]\n",
    "img = testImg.values.reshape(28, 28)\n",
    "print('----before reshape', img.shape, img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = img.reshape(1, 28, 28, 1).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted digit: 1 digit in csv: 1\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(img)\n",
    "predicted = np.argmax(predicted, axis=None, out=None)\n",
    "defined = trainData.iloc[index:(index+1), 0:1].values\n",
    "defined = np.squeeze(defined)\n",
    "print('predicted digit:', predicted,'digit in csv:', defined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
